head(testIndex)
testIndex = createDataPartition(diagnosis, p = 0.50,list=T)
head(testIndex)
head(testIndex)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
require(Hmisc)
a <- cut2(inTrain)
a
concrete$a <- cut2(inTrain)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
concrete$SuperPlasticizer
concrete$SuperPlasticizer
colnames(concrete)
concrete$Superplasticizer
hist(concrete$Superplasticizer)
hist(log(concrete$Superplasticizer))
hist(concrete$Superplasticizer)
par(mfcol=c(1,2))
hist(log(concrete$Superplasticizer))
hist(concrete$Superplasticizer)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(AlzheimerDisease)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(training)
str(training)
str(training[,57:68])
str(training[,58:69])
preProcess(training[,58:69], method='pca')
pca <- preProcess(training[,58:69], method='pca')
plot(pca)
predict(training[,58:69],pca)[,1]
predict(pca,training[,58:69])[,1]
predict(pca,training[,58:69])
pca.p <- predict(pca,training[,58:69])
plot(pca.p)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
concrete$Superplasticizer
par(mfcol=c(1,2))
hist(log(concrete$Superplasticizer))
hist(concrete$Superplasticizer)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=F)
head(testIndex)
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
require(Hmisc)
plot(training$Compre
plot(training$CompressiveStrength,pch=1,col=cut2(training$FlyAsh,m=20))
cut2(training$FlyAsh
)
plot(training$CompressiveStrength,pch=1,col=cut2(training$Age,m=20))
plot(training$CompressiveStrength,pch=1,col=cut2(training$Cement,m=20))
pca <- preProcess(training[,58:69], method='pca', pcaComp=2)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
str(training[,58:69])
pca <- preProcess(training[,58:69], method='pca', pcaComp=2)
pca.p <- predict(pca,training[,58:69])
plot(pca.p)
pca.p
pca <- preProcess(training[,58:69], method='pca')
pca.p <- predict(pca,training[,58:69])
plot(pca.p)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
str(training[,58:69])
pca <- preProcess(training[,58:69], method='pca')
pca.p <- predict(pca,training[,58:69])
plot(pca.p)
prcomp(training[,58:69])
pca$rotation
plot(prcomp(training[,58:69]))
svd1 <- svd(prcomp(training[,58:69]))
svd1 <- svd(scale(prcomp(training[,58:69])))
scale(prcomp(training[,58:69]))
svd1 <- svd(scale(training[,58:69]))
svd1
plot(svd1$d)
plot(svd1$d^2/sum(svd1$d^2))
svd1 <- svd(training[,58:69])
plot(svd1$d^2/sum(svd1$d^2))
scale
svd1 <- svd(scale(training[,58:69]))
plot(svd1$d^2/sum(svd1$d^2))
pca[,1]
pca
pca$rotation
plot(svd1$d^2/sum(svd1$d^2))
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
require(e1071)
fit <- svm(CompressiveStrength~., training)
pred <- predict(fit, testing)
# confusionMatrix(as.vector(pred), testing$CompressiveStrength)
sum(sqrt((pred-testing$CompressiveStrength)^2))
library(caret)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
require(e1071)
fit <- svm(CompressiveStrength~., training)
pred <- predict(fit, testing)
# confusionMatrix(as.vector(pred), testing$CompressiveStrength)
sum(sqrt((pred-testing$CompressiveStrength)^2))
sqrt(sum((pred-testing$CompressiveStrength)^2))
sqrt(107.44)
?colSums
?dgamma
?lm
?predict
?dgamma
?predict
?dgamma
pnorm(70, mean=80, sd=10, lower.tail=T)
pnorm(70, mean=80, sd=10, lower.tail=F)
qnorm(.95, mean=1000, sd=75)
qnorm(.95, mean=1000, sd=75, lower.tail = F)
qnorm(.95, mean=1000, sd=75, lower.tail = F)
T
qnorm(.95, mean=1000, sd=75, lower.tail = T)
qnorm(.95, mean=1100, sd=75, lower.tail = T)
qnorm(.95, mean=1100, sd=75, lower.tail = F)
qnorm(.95, mean=1100, sd=75, lower.tail = T)
pbinom(3, size = 5, prob = 0.5, lower.tail = FALSE)
ppois(2, lambda = 500 * 0.01)
pbinom(2, size = 500, prob = 0.01)
ppois(10, lambda = 5 * 3)
qnorm(.95, mean=1100, sd=75/sqrt(100), lower.tail = T)
round(pnorm(.51, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3
)# 9
round(pnorm(.51, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(pnorm(.5, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(qnorm(.5, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(qnorm(1000, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(pnorm(1000, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(pnorm(1, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(pnorm(0.5, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(pnorm(0.1, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(pnorm(0.9, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
round(pnorm(0.9, mean = 0.5, sd = sqrt(1 / 12 / 1000), lower.tail = FALSE), 3)
round(pnorm(0.51, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
51
round(pnorm(0.51, mean = 0.5, sd = sqrt(1 / 12 / 1000), lower.tail = FALSE), 3)
round(pnorm(0.5, mean = 0.5, sd = sqrt(1 / 12 / 1000), lower.tail = FALSE), 3)
setwd("C:\\Users\\Ivan.Liuyanfeng\\Desktop\\Data_Mining_Work_Space\\Data-Science-Statistical-Inference")
alpha = 0.05
z = qnorm(1 - alpha)
z
?qnorm
pnorm(mu0 + z * sigma/sqrt(n), mean = mua, sd = sigma/sqrt(n), lower.tail = FALSE)
mu0 = 30
mua = 32
sigma = 4
n = 16
alpha = 0.05
z = qnorm(1 - alpha)
pnorm(mu0 + z * sigma/sqrt(n), mean = mua, sd = sigma/sqrt(n), lower.tail = FALSE)
myplot <- function(sigma, mua, n, alpha) {
g = ggplot(data.frame(mu = c(27, 36)), aes(x = mu))
g = g + stat_function(fun = dnorm, geom = "line", args = list(mean = mu0,
sd = sigma/sqrt(n)), size = 2, col = "red")
g = g + stat_function(fun = dnorm, geom = "line", args = list(mean = mua,
sd = sigma/sqrt(n)), size = 2, col = "blue")
xitc = mu0 + qnorm(1 - alpha) * sigma/sqrt(n)
g = g + geom_vline(xintercept = xitc, size = 3)
g
}
manipulate(myplot(sigma, mua, n, alpha), sigma = slider(1, 10, step = 1, initial = 4),
mua = slider(30, 35, step = 1, initial = 32), n = slider(1, 50, step = 1,
initial = 16), alpha = slider(0.01, 0.1, step = 0.01, initial = 0.05))
library(manipulate)
library(manipulate)
mu0 = 30
myplot <- function(sigma, mua, n, alpha) {
g = ggplot(data.frame(mu = c(27, 36)), aes(x = mu))
g = g + stat_function(fun = dnorm, geom = "line", args = list(mean = mu0,
sd = sigma/sqrt(n)), size = 2, col = "red")
g = g + stat_function(fun = dnorm, geom = "line", args = list(mean = mua,
sd = sigma/sqrt(n)), size = 2, col = "blue")
xitc = mu0 + qnorm(1 - alpha) * sigma/sqrt(n)
g = g + geom_vline(xintercept = xitc, size = 3)
g
}
manipulate(myplot(sigma, mua, n, alpha), sigma = slider(1, 10, step = 1, initial = 4),
mua = slider(30, 35, step = 1, initial = 32), n = slider(1, 50, step = 1,
initial = 16), alpha = slider(0.01, 0.1, step = 0.01, initial = 0.05))
library(manipulate)
library(ggplot2)
mu0 = 30
myplot <- function(sigma, mua, n, alpha) {
g = ggplot(data.frame(mu = c(27, 36)), aes(x = mu))
g = g + stat_function(fun = dnorm, geom = "line", args = list(mean = mu0,
sd = sigma/sqrt(n)), size = 2, col = "red")
g = g + stat_function(fun = dnorm, geom = "line", args = list(mean = mua,
sd = sigma/sqrt(n)), size = 2, col = "blue")
xitc = mu0 + qnorm(1 - alpha) * sigma/sqrt(n)
g = g + geom_vline(xintercept = xitc, size = 3)
g
}
manipulate(myplot(sigma, mua, n, alpha), sigma = slider(1, 10, step = 1, initial = 4),
mua = slider(30, 35, step = 1, initial = 32), n = slider(1, 50, step = 1,
initial = 16), alpha = slider(0.01, 0.1, step = 0.01, initial = 0.05))
png('Power.png')
manipulate(myplot(sigma, mua, n, alpha), sigma = slider(1, 10, step = 1, initial = 4),
mua = slider(30, 35, step = 1, initial = 32), n = slider(1, 50, step = 1,
initial = 16), alpha = slider(0.01, 0.1, step = 0.01, initial = 0.05))
dev.off()
power.t.test(n = 16, delta = 2/4, sd = 1, type = "one.sample", alt = "one.sided")$power
power.t.test(n = 16, delta = 2/4, sd = 1, type = "one.sample", alt = "one.sided")
power.t.test(n = 16, delta = 2, sd = 4, type = "one.sample", alt = "one.sided")$power
power.t.test(n = 16, delta = 100, sd = 200, type = "one.sample", alt = "one.sided")$power
power.t.test(power = 0.8, delta = 2/4, sd = 1, type = "one.sample", alt = "one.sided")$n
power.t.test(power = 0.8, delta = 2, sd = 4, type = "one.sample", alt = "one.sided")$n
power.t.test(power = 0.8, delta = 100, sd = 200, type = "one.sample", alt = "one.sided")$n
set.seed(1010093)
pValues <- rep(NA, 1000)
pValues
for (i in 1:1000) {
y <- rnorm(20)
x <- rnorm(20)
pValues[i] <- summary(lm(y ~ x))$coeff[2, 4]
}
pValues
sum(pValues < 0.05)
sum(p.adjust(pValues, method = "bonferroni") < 0.05)
sum(p.adjust(pValues, method = "BH") < 0.05)
set.seed(1010093)
pValues <- rep(NA, 1000)
for (i in 1:1000) {
x <- rnorm(20)
# First 500 beta=0, last 500 beta=2
if (i <= 500) {
y <- rnorm(20)
} else {
y <- rnorm(20, mean = 2 * x)
}
pValues[i] <- summary(lm(y ~ x))$coeff[2, 4]
}
trueStatus <- rep(c("zero", "not zero"), each = 500)
table(pValues < 0.05, trueStatus)
# Controls FWER
table(p.adjust(pValues, method = "bonferroni") < 0.05, trueStatus)
table(p.adjust(pValues, method = "BH") < 0.05, trueStatus)
par(mfrow = c(1, 2))
plot(pValues, p.adjust(pValues, method = "bonferroni"), pch = 19)
plot(pValues, p.adjust(pValues, method = "BH"), pch = 19)
png('adj_pvalue.png')
par(mfrow = c(1, 2))
plot(pValues, p.adjust(pValues, method = "bonferroni"), pch = 19)
plot(pValues, p.adjust(pValues, method = "BH"), pch = 19)
dev.off()
sum(p.adjust(pValues, method = "BY") < 0.05)
sum(pValues < 0.05)
sum(p.adjust(pValues, method = "bonferroni") < 0.05)
sum(p.adjust(pValues, method = "BH") < 0.05)
table(p.adjust(pValues, method = "BY") < 0.05, trueStatus)
source('~/.active-rstudio-document', echo=TRUE)
library(UsingR)
data(father.son)
x <- father.son$sheight
n <- length(x)
n
theta <- median(x)
theta
jk <- sapply(1:n, function(i) median(x[-i]))
jk
thetaBar <- mean(jk)
thetaBar
biasEst <- (n - 1) * (thetaBar - theta)
biasEst
seEst <- sqrt((n - 1) * mean((jk - thetaBar)^2))
seEst
c(biasEst, seEst)
library(bootstrap)
temp <- jackknife(x, median)
install.packages('bootstap')
install.packages('bootstrap')
library(bootstrap)
temp <- jackknife(x, median)
temp
c(temp$jack.bias, temp$jack.se)
B <- 1000
resamples <- matrix(sample(x, n * B, replace = TRUE), B, n)
resamples
sample(x, n * B, replace = TRUE)
medians <- apply(resamples, 1, median)
medians
sd(medians)
quantile(medians, c(0.025, 0.975))
hist(medians)
par(mfcol=c(1,1))
par(mfcol=c(1,1))
png('bootstrap.png')
hist(medians)
dev.off()
hist(medians)
data(InsectSprays)
boxplot(count ~ spray, data = InsectSprays)
subdata <- InsectSprays[InsectSprays$spray %in% c("B", "C"), ]
subdata
y <- subdata$count
y
group <- as.character(subdata$spray)
group
testStat <- function(w, g) mean(w[g == "B"]) - mean(w[g == "C"])
observedStat <- testStat(y, group)
observedStat
permutations <- sapply(1:10000, function(i) testStat(y, sample(group)))
sample(group)
observedStat
mean(permutations > observedStat)
hist(permutations)
hist(observedStat)
png('permutation.png')
hist(permutations)
dev.off()
setwd("C:\\Users\\Ivan.Liuyanfeng\\Desktop\\Data_Mining_Work_Space\\Data-Science-Statistical-Inference")
library(datasets)
data(mtcars)
mn<- mean(mtcars$mpg)
mn
z <- qnorm(.05)
z
s <- sd(mtcars$mpg)
mu0 <- mn-z*s/sqrt(nrow(mtcars))
mu0
m4 <- mtcars$mpg[mtcars$cyl==4.]
m6 <- mtcars$mpg[mtcars$cyl==6.]
p <- t.test(m4,m6, paired=F, alternative='two.sided',var.equal = F)
p
z <- .05
avg + c(-1,1)*qnorm(z)*sqrt((n*sd)/n)*(1/n)^.5
n <- 100
avg <- 3
sd <- 1.1
z <- .05
avg + c(-1,1)*qnorm(z)*sqrt((n*sd)/n)*(1/n)^.5
avg + c(-1,1)*qnorm(z)*sqrt((n*sd)/n)
avg + c(-1,1)*qnorm(z/2)*sqrt((n*sd)/n)*(1/n)^.5
avg + c(-1,1)*qnorm(.025)*sqrt((n*sd)/n)*(1/n)^.5
avg + c(-1,1)*qnorm(.05)*sqrt((n*sd)/n)*(1/n)^.5
ans <- round(pbinom(54, prob = .5, size = 100, lower.tail = FALSE),4)
ans
pv <- ppois(15800 - 1, lambda = 520 * 30, lower.tail = FALSE)
pv
pnorm(15800 / 30, mean = 520, sd = sqrt(520 / 30), lower.tail = FALSE)
m1 <- 10; m2 <- 11
n1 <- n2 <- 100
s <- 4
se <- s * sqrt(1 / n1 + 1 / n2)
se
ts <- (m2 - m1) / se
ts
pv <- 2 * pnorm(-abs(ts))
pv
qnorm(.95)
power <- pnorm(10 + qnorm(.95) * .4, mean = 11, sd = .4, lower.tail = FALSE)
power
power <- pnorm(10 + qnorm(.95) * 4, mean = 11, sd = 4, lower.tail = FALSE)
power
.
n <- (qnorm(.95) + qnorm(.8)) ^ 2 * .04 ^ 2 / .01^2
n
power.t.test(power = 0.8, delta = 2/4, sd = .04, type = "one.sample", alt = "one.sided")$n
(qnorm(.95) + qnorm(.8))
qnorm(.95)
qnorm(.8)
p <- t.test(mpg8, mpg6, paired = FALSE, alternative="two.sided", var.equal=TRUE)$p.value
mpg8 <- mtcars$mpg[mtcars$cyl==8,]
mpg8 <- mtcars$mpg[mtcars$cyl==8]
mpg6 <- mtcars$mpg[mtcars$cyl==6]
p <- t.test(mpg8, mpg6, paired = FALSE, alternative="two.sided", var.equal=TRUE)$p.value
p
mixprob <- (n8 - 1) / (n8 + n6 - 2)
a <- c(140,138,150,148,135)
b <- c(132, 135,151,146,130)
t.test(a,b,paired=T,var.equal = T)
z <- qt(.025,n)
m <- 1100
s <- 30
n <- 9
z <- qt(.025,n)
z
z <- pt(.025,n)
z
z <- qt(.025,n)
m + c(-1,1)*z*sqrt((n*s^2)/n)*(1/n)^.5
z <- qt(.975,n)
m + c(-1,1)*z*sqrt((n*s^2)/n)*(1/n)^.5
coke <- c(1,1,1,0)
pessi <- c(0,0,0,1)
t.test(coke,pessi)
t.test(coke,pessi,var.equal = TRUE)
t.test(coke,pessi,var.equal = TRUE, paired=T)
pt(0.8, 15, lower.tail = FALSE)
pbinom(6, size = 8, prob = 0.5, lower.tail = FALSE)
ppois(9, 5, lower.tail = FALSE)
pbinom(10, size = 1787, prob = 0.01, lower.tail = FALSE)
1-pbinom(10, size = 1787, prob = 0.01, lower.tail = FALSE)
n=9
n<-9
pt(0.95, 18, lower.tail = FALSE)
power.t.test(n = 100, delta = .01, sd = .04, type = "one.sample", alt = "one.sided")$power
?power.t.test
power.t.test(n = 100, delta = -.01, sd = .04, type = "one.sample", alt = "one.sided")$power
power.t.test(n = 100, delta = -0.01, sd = .04, type = "one.sample", alt = "one.sided")$power
power.t.test(n = 100, delta = 0.01, sd = .04, type = "one.sample", alt = "one.sided")$power
power.t.test(power = 0.9, delta = .01, sd = .04, type = "one.sample", alt = "one.sided")$n
s <- 12
ma <- 44
mb <- 42.04
n <- 288
?pnorm
m.t <- -3
m.p <- 1
s.t <- 1.5
s.p <- 1.8
n<-9
pt(0.95, 18, lower.tail = FALSE)
se <- s/sqrt(n)
se
z <- (ma-mb)/se
z
z <- (mb-ma)/se
z
b
z <- (ma-mb)/se
z <- (ma-mb)/s
z
se <- s/n
z <- (ma-mb)/se
z
s <- 12
ma <- 44
mb <- 42.04
n <- 288
se <- s/n
z <- (ma-mb) / (s * sqrt(1 / n + 1 / n))
z
pz <- 2 * pnorm(-abs(z))
pz
p.adjust(0.05, method = "BY")
p.adjust(0.05, method = "bonferroni")
p.adjust(0.05, method = "BH")
m4 <- rnorm(n, m.t,s.t)
m4 <- rnorm(n, m.t,s.t)
m6 <- rnorm(n, m.p,s.p)
p <- t.test(m4, m6, paired = FALSE, alternative="two.sided", var.equal=FALSE)$p.value
p
